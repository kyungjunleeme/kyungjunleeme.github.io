틀린것을 모델에 적용
모델에 데이터가 들어가면 예측하고, 

Chapter 01. 인공지능 개념이해 - 03. 딥러닝 용어 - 1
Model 

Layer는 깊으면 깊을수록 좋다고는 하지만, 

성능적으로도 

합성곱

이미지가 필터를 받으면 곱해주고 나면 

> 이런 경우 테두리를 잡아주는 필터

합성곱을 이용해서 만든거다

이런 테두리를 잡앗는데 

weight는 학습하려는 대상 variable 처럼

filter가 공정된 값이 아니라, feautrue를 더 뽑으려고함

이 filter가 계산을통해서 성ㄴ으을 높이는 거다 

데이터의 목적에 따라 weight를 학습을 시켜야 함

Weight가 중요한 역할을 함

Convolution 안에 weight를 학습시킨다

y = wx + b

w = weight
b = bias

padding이 잇냐 없냐에 따라서

pooling layer를 

높은 수치들을 가진 값들ㅇ르 반으로 줄여준다

반사이즈의 이미지로 줄여준다는 의미 

convolution은 특징을 뽑는층

pooling은 압축을 하는 층

optimization은 인공지능을 학습시키고 나서

activation Function

Softmax

Loss Fucntion
> 

Optimization 이 

Hyper parameter 학습을 할 때 직접 조정해줘야한다. 

그중 하나가 Learning Rate 이다.

Batch Size 몇 장을 한 번에 학습 시킬 것인가?

Epoch / Step

Epoch 인공지능도 여러 번 반복해서 공부해야 함 

반복 횟수

Label / Ground Truth : 정답이 있어야 함

데이터에 대한 정답을 줘야 함

모든 데이터 셋에 대해 정답이 있어야 함

CNN은 크게
Feature Extraction 
Feature Extraction in multiple hidden layers
딥러닝은 블랙박스다 딥러닝이 여러 특징을 뽑아낸다.
Convolution Layer
Pooling Layer 
앞에서 특징들ㅇ르 뽑앗으면, 그 중에서 그것을 반으로 ㅈ루임 그 안에 특징 값이 젱리 큰것을 뽑은 이미지를 압축을 한다고 생각하면 됨

Activation function
Lelu 불필요한 것을 없앤다고 생각하면 됨 
Label(정답)에 맞도록 w와 b를 조정함

LeNet

마지막에 Fully Connected로 계싼을 해서 예측을 함 

/ Classification으로 나눠져 있음
Classification in the output layer

특징을 뽑는 과정이 

주피터 노트북 단축키

shift + m => 셀 병합

shiit + ctrl + - 는 커서를 중심으로 split

command 모드 파란색
>> command 모드에서 a 누르면 위에 셀 생기고, b 누르면 아래에 셀 생김
편집 모드 초록색


